# Глава 17: Техники рассуждений

Данная глава углубляется в продвинутые методологии рассуждений для интеллектуальных агентов, фокусируясь на многошаговых логических выводах и решении проблем. Эти техники выходят за рамки простых последовательных операций, делая внутренний процесс рассуждений агента явным. Это позволяет агентам разбивать проблемы, рассматривать промежуточные шаги и приходить к более надежным и точным выводам. Основополагающим принципом среди этих продвинутых методов является выделение увеличенных вычислительных ресурсов во время инференса.

Это означает предоставление агенту или базовой LLM больше времени на обработку или шагов для обработки запроса и генерации ответа. Вместо быстрого, одноразового прохода агент может заниматься итеративным уточнением, исследовать множественные пути решения или использовать внешние инструменты. Это расширенное время обработки во время инференса часто значительно повышает точность, связность и надежность, особенно для сложных проблем, требующих более глубокого анализа и обдумывания.

## Практические применения и случаи использования

Практические применения включают:

- **Комплексные ответы на вопросы:** Облегчение решения многошаговых запросов, которые требуют интеграции данных из различных источников и выполнения логических выводов, потенциально включающих изучение множественных путей рассуждений, и получающих пользу от расширенного времени инференса для синтеза информации.

- **Решение математических задач:** Обеспечение разделения математических проблем на более мелкие, решаемые компоненты, иллюстрируя пошаговый процесс, и использование выполнения кода для точных вычислений, где продолжительный инференс позволяет более сложную генерацию и валидацию кода.

- **Отладка и генерация кода:** Поддержка объяснения агентом своего обоснования для генерации или исправления кода, выявления потенциальных проблем последовательно, и итеративного уточнения кода на основе результатов тестирования (самокоррекция), использующего расширенное время инференса для тщательных циклов отладки.

- **Стратегическое планирование:** Помощь в разработке комплексных планов через рассуждения по различным вариантам, последствиям и предварительным условиям, и корректировке планов на основе обратной связи в реальном времени (ReAct), где расширенное обдумывание может привести к более эффективным и надежным планам.

- **Медицинская диагностика:** Помощь агенту в систематической оценке симптомов, результатов тестов и истории пациентов для постановки диагноза, артикулируя свое рассуждение на каждом этапе, и потенциально используя внешние инструменты для получения данных (ReAct). Увеличенное время инференса позволяет более комплексную дифференциальную диагностику.

- **Правовой анализ:** Поддержка анализа правовых документов и прецедентов для формулирования аргументов или предоставления руководства, детализируя предпринятые логические шаги, и обеспечивая логическую согласованность через самокоррекцию. Увеличенное время инференса позволяет более углубленное правовое исследование и построение аргументов.

## Техники рассуждений

Для начала давайте углубимся в основные техники рассуждений, используемые для улучшения способностей решения проблем AI-моделей.

**Chain-of-Thought (CoT)** промптинг значительно улучшает способности сложных рассуждений LLM, имитируя пошаговый мыслительный процесс (см. Рис. 1). Вместо предоставления прямого ответа, CoT промпты направляют модель к генерации последовательности промежуточных шагов рассуждения. Эта явная разбивка позволяет LLM справляться со сложными проблемами, разлагая их на более мелкие, более управляемые подпроблемы. Эта техника заметно улучшает производительность модели на задачах, требующих многошаговых рассуждений, таких как арифметика, рассуждения здравого смысла и символические манипуляции.

Основное преимущество CoT - его способность трансформировать сложную, одношаговую проблему в серию более простых шагов, тем самым увеличивая прозрачность процесса рассуждений LLM. Этот подход не только повышает точность, но также предлагает ценные инсайты в принятие решений модели, помогая в отладке и понимании.

CoT может быть реализован с использованием различных стратегий, включая предложение примеров few-shot, которые демонстрируют пошаговые рассуждения, или просто инструктирование модели "думать пошагово". Его эффективность проистекает из его способности направлять внутреннюю обработку модели к более обдуманному и логическому прогрессу. В результате Chain-of-Thought стал краеугольной техникой для обеспечения продвинутых возможностей рассуждений в современных LLM. Эта улучшенная прозрачность и разбивка сложных проблем на управляемые подпроблемы особенно важна для автономных агентов, поскольку это позволяет им выполнять более надежные и проверяемые действия в сложных средах.

![][image2]

Рис. 1: CoT промпт вместе с детализированным, пошаговым ответом, сгенерированным агентом.

Давайте посмотрим пример. Он начинается с набора инструкций, которые говорят AI, как думать, определяя его персону и ясный пятишаговый процесс для следования. Это промпт, который инициирует структурированное мышление.

Следуя этому, пример показывает процесс CoT в действии. Раздел, помеченный "Мыслительный процесс агента", является внутренним монологом, где модель выполняет инструктированные шаги. Это буквальная "цепочка мыслей". Наконец, "Финальный ответ агента" - это отполированный, комплексный вывод, сгенерированный в результате этого тщательного, пошагового процесса рассуждения.

```
Вы - агент поиска информации. Ваша цель - отвечать на вопросы пользователя исчерпывающе и точно, думая пошагово.

Вот процесс, которому вы должны следовать:

1. **Анализ запроса:** Поймите основную тему и специфические требования вопроса пользователя. Определите ключевые сущности, ключевые слова и тип искомой информации.

2. **Формулировка поисковых запросов (для базы знаний):** На основе вашего анализа сгенерируйте список точных поисковых запросов, которые вы бы использовали для получения релевантной информации из базы знаний или внешних инструментов.

3. **Симуляция поиска информации (самокоррекция/рассуждение):** Для каждого поискового запроса мысленно рассмотрите, какого рода информацию вы ожидаете найти. Если бы вы получили содержимое, какими были бы наиболее релевантные фрагменты? Подумайте о потенциальных неоднозначностях или недостающих частях.

4. **Синтез информации:** На основе симулированного поиска и вашего понимания исходного запроса пользователя синтезируйте собранную информацию в связный и полный ответ. Убедитесь, что все аспекты запроса рассмотрены.

5. **Обзор и уточнение:** Перед финализацией критически оцените ваш ответ. Является ли он точным? Является ли он исчерпывающим? Легко ли он понимается? Является ли он лаконичным? Если нет, определите, что нужно улучшить и как.

**Запрос пользователя:** "Объясните основные различия между классическими компьютерами и квантовыми компьютерами, и кратко опишите потенциальное применение квантовых вычислений."

**Мыслительный процесс агента (внутренний CoT вывод - поощряемый промптом):**

**Мысль 1 (Анализ запроса):**
Пользователь хочет две вещи:
1. Основные различия между классическими и квантовыми компьютерами.
2. Одно потенциальное применение квантовых вычислений.
Ключевые слова: классические компьютеры, квантовые компьютеры, различия, потенциальное применение.

**Мысль 2 (Формулировка поисковых запросов):**
- "различия классические против квантовые компьютеры"
- "как работают квантовые компьютеры"
- "как работают классические компьютеры"
- "применения квантовых вычислений"

**Мысль 3 (Симуляция поиска информации и определение ключевых концепций):**
- Из "различий": Ожидаю концепции как биты против кубитов, суперпозиция, запутанность, вероятностная природа, вычислительная мощность для специфических проблем.
- Из "как они работают": Классические используют транзисторы/бинарные. Квантовые используют квантовую механику.
- Из "применений": Ожидаю открытие лекарств, материаловедение, криптографию, оптимизацию.

**Мысль 4 (Синтез информации):**
Классические компьютеры используют биты (0 или 1), обрабатывая информацию последовательно. Квантовые компьютеры используют кубиты, которые могут быть 0, 1 или обоими одновременно (суперпозиция), и могут быть запутанными, позволяя кардинально разные вычислительные подходы. Это позволяет им решать определенные проблемы (как факторизация больших чисел или симуляция сложных молекул) гораздо более эффективно, чем классические компьютеры. Потенциальное применение - в открытии лекарств, где квантовые компьютеры могли бы симулировать молекулярные взаимодействия с беспрецедентной точностью, ускоряя разработку новых лекарств.

**Мысль 5 (Обзор и уточнение):**
- Различия покрыты (биты против кубитов, суперпозиция, запутанность, обработка).
- Применение дано (открытие лекарств).
- Является ли это кратким? Да.
- Является ли это ясным? Да.
- Выглядит хорошо.

**Финальный ответ агента (вывод пользователю):**

Классические компьютеры обрабатывают информацию, используя биты, которые могут быть либо 0, либо 1 в любой данный момент времени, выполняя операции последовательно. В противоположность этому, квантовые компьютеры используют кубиты, которые могут существовать в множественных состояниях одновременно через суперпозицию и могут быть связаны через запутанность, позволяя экспоненциально более сложные вычисления. Это фундаментальное различие позволяет квантовым машинам справляться с определенными проблемами, такими как симуляция молекулярных структур или взлом сложного шифрования, которые неразрешимы даже для самых мощных классических суперкомпьютеров. Значительное потенциальное применение квантовых вычислений лежит в открытии лекарств, где их способность точно моделировать поведение молекул могла бы революционизировать разработку новых фармацевтических препаратов.
```

**Tree-of-Thought (ToT)** - это техника рассуждений, которая строится на Chain-of-Thought (CoT). Она позволяет большим языковым моделям исследовать множественные пути рассуждений, ветвясь на различные промежуточные шаги, формируя древовидную структуру (см. Рис. 2). Этот подход поддерживает сложное решение проблем, позволяя откат назад, самокоррекцию и исследование альтернативных решений. Поддержание дерева возможностей позволяет модели оценивать различные траектории рассуждений перед финализацией ответа. Этот итеративный процесс улучшает способность модели справляться с вызывающими задачами, которые требуют стратегического планирования и принятия решений.

![][image1]

Рис. 2: Пример Tree of Thoughts

**Самокоррекция**, также известная как самоуточнение, является критически важным аспектом процесса рассуждений агента, особенно в рамках Chain-of-Thought промптинга. Она включает внутреннюю оценку агентом своего сгенерированного содержимого и промежуточных мыслительных процессов. Этот критический обзор позволяет агенту выявлять неоднозначности, пробелы в информации или неточности в своем понимании или решениях. Этот итеративный цикл обзора и уточнения позволяет агенту корректировать свой подход, улучшать качество ответа и обеспечивать точность и тщательность перед доставкой финального вывода. Эта внутренняя критика улучшает способность агента производить надежные и высококачественные результаты, как продемонстрировано в примерах в посвященной Главе 4.

Этот пример демонстрирует систематический процесс самокоррекции, критически важный для уточнения AI-генерированного содержимого. Он включает итеративный цикл создания черновика, обзора против исходных требований и реализации специфических улучшений. Иллюстрация начинается с обрисовки функции AI как "Агента самокоррекции" с определенным пятишаговым аналитическим и пересмотровым рабочим процессом. Следуя этому, представлен неудовлетворительный "Начальный черновик" поста в социальных сетях. "Мыслительный процесс агента самокоррекции" формирует ядро демонстрации. Здесь агент критически оценивает черновик согласно своим инструкциям, выявляя слабости, такие как низкая вовлеченность и расплывчатый призыв к действию. Затем он предлагает конкретные улучшения, включая использование более импактных глаголов и эмодзи. Процесс завершается "Финальным пересмотренным содержимым" - отполированной и заметно улучшенной версией, которая интегрирует самоопределенные корректировки.

```
Вы - высоко критичный и внимательный к деталям агент самокоррекции. Ваша задача - обзор ранее сгенерированного содержимого против его исходных требований и определение областей для улучшения. Ваша цель - уточнить содержимое, чтобы оно было более точным, исчерпывающим, вовлекающим и соответствующим промпту.

Вот процесс, которому вы должны следовать для самокоррекции:

1. **Понимание исходных требований:** Обзор начального промпта/требований, которые привели к созданию содержимого. Каково было *исходное намерение*? Каковы были ключевые ограничения или цели?

2. **Анализ текущего содержимого:** Внимательно прочитайте предоставленное содержимое.

3. **Определение расхождений/слабостей:** Сравните текущее содержимое с исходными требованиями. Ищите:
   * **Проблемы точности:** Есть ли какие-либо фактические ошибки или вводящие в заблуждение утверждения?
   * **Пробелы в полноте:** Полностью ли оно рассматривает все аспекты исходного промпта? Что-то отсутствует?
   * **Ясность и связность:** Является ли язык ясным, лаконичным и легким для понимания? Течет ли он логично?
   * **Тон и стиль:** Соответствует ли он желаемому тону и стилю (например, профессиональный, вовлекающий, лаконичный)?
   * **Вовлеченность:** Является ли оно захватывающим? Удерживает ли оно внимание читателя?
   * **Избыточность/многословность:** Можно ли какие-то части сжать или удалить без потери смысла?

4. **Предложение специфических улучшений:** Для каждой выявленной слабости предложите конкретные и действенные изменения. Не просто указывайте проблему; предложите решение.

5. **Генерация пересмотренного содержимого:** На основе ваших предложенных улучшений перепишите исходное содержимое, чтобы включить все необходимые изменения. Убедитесь, что пересмотренное содержимое отполировано и готово к финальному использованию.

**Исходный промпт/требования:** "Напишите короткий, вовлекающий пост в социальных сетях (максимум 150 символов), объявляющий новую экологически чистую линейку продуктов: 'GreenTech Gadgets'."

**Начальный черновик (содержимое для коррекции):**

"У нас есть новые продукты. Они зеленые и технологичные. Покупайте GreenTech Gadgets сейчас!"

**Мыслительный процесс агента самокоррекции (внутренний CoT вывод - поощряемый промптом):**

**Мысль 1 (Понимание исходных требований):**
- Короткий, вовлекающий пост в социальных сетях.
- Максимум 150 символов.
- Объявить "GreenTech Gadgets" - новую экологически чистую линейку продуктов.

**Мысль 2 (Анализ текущего содержимого):**
"У нас есть новые продукты. Они зеленые и технологичные. Покупайте GreenTech Gadgets сейчас!" (64 символа)

**Мысль 3 (Определение расхождений/слабостей):**
- **Вовлекающий:** Не очень вовлекающий. Звучит обобщенно.
- **Экологически чистый:** Подразумевается "зеленым", но не явно выделено как преимущество.
- **Призыв к действию:** "Покупайте сейчас!" - нормально, но может быть более убедительным.
- **Лаконичность:** Он короткий, но может использовать более сильные глаголы/формулировки.
- **Воздействие:** Недостает возбуждения для запуска нового продукта.

**Мысль 4 (Предложение специфических улучшений):**
- Сделать его более динамичным и возбуждающим.
- Подчеркнуть "экологически чистый" и "инновацию".
- Использовать более сильные глаголы и более активный залог.
- Добавить ясный, вовлекающий призыв к действию.
- Убедиться, что он остается под 150 символами.

**Мысль 5 (Генерация пересмотренного содержимого):**
Исходный: "У нас есть новые продукты. Они зеленые и технологичные. Покупайте GreenTech Gadgets сейчас!"
Пересмотренная идея 1: "🌱 Откройте GreenTech Gadgets! Наша новая экологически чистая линейка сочетает инновации с устойчивостью. Станьте зелеными, станьте умными! Покупайте сейчас! #EcoFriendly #GreenTech" (148 символов)
Эта ревизия напрямую адресует экологичность, использует эмодзи для вовлеченности, добавляет более сильный призыв к действию и включает релевантные хештеги, оставаясь в пределах лимита символов.

**Финальное пересмотренное содержимое агента самокоррекции (вывод пользователю):**

🌱 Откройте GreenTech Gadgets! Наша новая экологически чистая линейка сочетает инновации с устойчивостью. Станьте зелеными, станьте умными! Покупайте сейчас! #EcoFriendly #GreenTech
```

Фундаментально, эта техника интегрирует меру контроля качества непосредственно в генерацию содержимого агентом, давая более уточненные, точные и превосходные результаты, которые более эффективно встречают сложные пользовательские требования.

**Program-Aided Language Models (PALMs)** интегрируют LLM с возможностями символических рассуждений. Эта интеграция позволяет LLM генерировать и выполнять код, такой как Python, как часть своего процесса решения проблем. PALM передают сложные вычисления, логические операции и манипуляции данными в детерминистическую программную среду. Этот подход использует сильные стороны традиционного программирования для задач, где LLM могут проявлять ограничения в точности или согласованности. Когда сталкиваются с символическими вызовами, модель может производить код, выполнять его и конвертировать результаты в естественный язык. Эта гибридная методология сочетает способности понимания и генерации LLM с точными вычислениями, позволяя модели решать более широкий спектр сложных проблем с потенциально повышенной надежностью и точностью. Это важно для агентов, поскольку позволяет им выполнять более точные и надежные действия, используя точные вычисления наряду с их способностями понимания и генерации. Пример - использование внешних инструментов в Google ADK для генерации кода.

```python
from google.adk.tools import agent_tool
from google.adk.agents import Agent
from google.adk.tools import google_search
from google.adk.code_executors import BuiltInCodeExecutor

search_agent = Agent(
    model='gemini-2.0-flash',
    name='SearchAgent',
    instruction="""
    Вы - специалист по Google Search
    """,
    tools=[google_search],
)

coding_agent = Agent(
    model='gemini-2.0-flash',
    name='CodeAgent',
    instruction="""
    Вы - специалист по выполнению кода
    """,
    code_executor=[BuiltInCodeExecutor],
)

root_agent = Agent(
    name="RootAgent",
    model="gemini-2.0-flash",
    description="Корневой агент",
    tools=[agent_tool.AgentTool(agent=search_agent), agent_tool.AgentTool(agent=coding_agent)],
)
```

**Reinforcement Learning with Verifiable Rewards (RLVR):** Хотя и эффективный, стандартный Chain-of-Thought (CoT) промптинг, используемый многими LLM, является несколько базовым подходом к рассуждениям. Он генерирует единую, предопределенную линию мысли без адаптации к сложности проблемы. Для преодоления этих ограничений был разработан новый класс специализированных "моделей рассуждений". Эти модели работают по-другому, посвящая переменное количество времени "мышления" перед предоставлением ответа. Этот процесс "мышления" производит более обширную и динамичную Chain-of-Thought, которая может быть тысячи токенов длиной. Это расширенное рассуждение позволяет более сложное поведение, такое как самокоррекция и откат назад, с моделью, посвящающей больше усилий более сложным проблемам.

Ключевая инновация, обеспечивающая эти модели, - это стратегия обучения, называемая Reinforcement Learning from Verifiable Rewards (RLVR). Обучая модель на проблемах с известными правильными ответами (как математика или код), она учится через пробы и ошибки генерировать эффективные, длинные рассуждения. Это позволяет модели развивать свои способности решения проблем без прямого человеческого надзора. В конечном счете, эти модели рассуждений не просто производят ответ; они генерируют "траекторию рассуждений", которая демонстрирует продвинутые навыки, такие как планирование, мониторинг и оценка. Эта улучшенная способность рассуждать и стратегизировать является фундаментальной для развития автономных AI агентов, которые могут разбивать и решать сложные задачи с минимальным человеческим вмешательством.

**ReAct** (Reasoning and Acting, см. Рис. 3, где KB означает Knowledge Base) - это парадигма, которая интегрирует Chain-of-Thought (CoT) промптинг со способностью агента взаимодействовать с внешними средами через инструменты. В отличие от генеративных моделей, которые производят финальный ответ, ReAct агент рассуждает о том, какие действия предпринять. Эта фаза рассуждений включает внутренний процесс планирования, похожий на CoT, где агент определяет свои следующие шаги, рассматривает доступные инструменты и предвидит результаты. Следуя этому, агент действует, выполняя вызов инструмента или функции, такой как запрос к базе данных, выполнение вычисления или взаимодействие с API.

![][image3]

Рис. 3: Reasoning and Act

ReAct работает в переплетенной манере: агент выполняет действие, наблюдает результат и включает это наблюдение в последующие рассуждения. Эта итеративная петля "Мысль, Действие, Наблюдение, Мысль..." позволяет агенту динамически адаптировать свой план, исправлять ошибки и достигать целей, требующих множественных взаимодействий со средой. Это обеспечивает более надежный и гибкий подход к решению проблем по сравнению с линейным CoT, поскольку агент реагирует на обратную связь в реальном времени. Комбинируя понимание и генерацию языковой модели со способностью использовать инструменты, ReAct позволяет агентам выполнять сложные задачи, требующие как рассуждений, так и практического выполнения. Этот подход критически важен для агентов, поскольку позволяет им не только рассуждать, но и практически выполнять шаги и взаимодействовать с динамическими средами.

**CoD** (Chain of Debates) - это формальная AI-платформа, предложенная Microsoft, где множественные, разнообразные модели сотрудничают и спорят для решения проблемы, выходя за рамки "цепочки мыслей" одного AI. Эта система работает как совет AI, где различные модели представляют начальные идеи, критикуют рассуждения друг друга и обмениваются контраргументами. Основная цель - улучшить точность, уменьшить предвзятость и улучшить общее качество финального ответа, используя коллективный интеллект. Функционируя как AI-версия экспертной оценки, этот метод создает прозрачную и заслуживающую доверия запись процесса рассуждений. В конечном счете, он представляет сдвиг от одиночного агента, предоставляющего ответ, к совместной команде агентов, работающих вместе для поиска более надежного и проверенного решения.

**GoD** (Graph of Debates) - это продвинутая агентная платформа, которая переосмысливает дискуссию как динамическую, нелинейную сеть, а не простую цепочку. В этой модели аргументы являются индивидуальными узлами, соединенными ребрами, которые означают отношения, такие как "поддерживает" или "опровергает", отражая многопоточную природу реальных дебатов. Эта структура позволяет новым линиям исследования динамически ответвляться, развиваться независимо и даже сливаться со временем. Заключение достигается не в конце последовательности, а путем определения наиболее надежного и хорошо поддерживаемого кластера аргументов в пределах всего графа.

В этом контексте "хорошо поддерживаемый" относится к знаниям, которые прочно установлены и проверяемы. Это может включать информацию, считающуюся основополагающей истиной, что означает, что она по своей природе правильна и широко принята как факт. Дополнительно, это охватывает фактические доказательства, полученные через поисковое обоснование, где информация валидируется против внешних источников и реальных данных. Наконец, это также относится к консенсусу, достигнутому множественными моделями во время дебатов, указывая на высокую степень согласия и уверенности в представленной информации. Этот комплексный подход обеспечивает более надежную и достоверную основу для обсуждаемой информации. Этот подход обеспечивает более холистическую и реалистичную модель для сложных, совместных AI рассуждений.

**MASS (дополнительная продвинутая тема):** Углубленный анализ проектирования многоагентных систем показывает, что их эффективность критически зависит как от качества промптов, используемых для программирования индивидуальных агентов, так и от топологии, которая диктует их взаимодействия. Сложность проектирования этих систем значительна, поскольку включает обширное и сложное пространство поиска. Для решения этого вызова была разработана новая платформа под названием Multi-Agent System Search (MASS) для автоматизации и оптимизации проектирования MAS.

MASS использует многоэтапную стратегию оптимизации, которая систематически навигирует сложное пространство проектирования путем переплетения оптимизации промптов и топологии (см. Рис. 4).

### 1. Блочная оптимизация промптов:

Процесс начинается с локальной оптимизации промптов для индивидуальных типов агентов, или "блоков", чтобы убедиться, что каждый компонент эффективно выполняет свою роль перед интеграцией в большую систему. Этот начальный шаг критически важен, поскольку обеспечивает, что последующая оптимизация топологии строится на хорошо работающих агентах, а не страдает от составного воздействия плохо настроенных. Например, при оптимизации для датасета HotpotQA промпт для агента "Дебатёр" творчески сформулирован, чтобы инструктировать его действовать как "эксперт по проверке фактов для крупного издания". Его оптимизированная задача - тщательно обзор предложенных ответов от других агентов, перекрестная ссылка с предоставленными контекстными отрывками и выявление любых несоответствий или неподдерживаемых утверждений. Этот специализированный ролевой промпт, обнаруженный во время блочной оптимизации, направлен на то, чтобы сделать агента-дебатёра высоко эффективным в синтезе информации перед тем, как он даже будет помещен в больший рабочий процесс.

### 2. Оптимизация топологии рабочего процесса:

Следуя локальной оптимизации, MASS оптимизирует топологию рабочего процесса, выбирая и организуя различные взаимодействия агентов из настраиваемого пространства проектирования. Чтобы сделать этот поиск эффективным, MASS использует метод, взвешенный влиянием. Этот метод вычисляет "инкрементальное влияние" каждой топологии, измеряя её прирост производительности относительно базового агента и использует эти оценки для направления поиска к более перспективным комбинациям. Например, при оптимизации для задачи кодирования MBPP поиск топологии обнаруживает, что специфический гибридный рабочий процесс наиболее эффективен. Лучшая найденная топология не является простой структурой, а комбинацией итеративного процесса уточнения с использованием внешних инструментов. Конкретно, она состоит из одного агента-предсказателя, который участвует в нескольких раундах рефлексии, с его кодом, проверяемым одним агентом-исполнителем, который запускает код против тестовых случаев. Этот обнаруженный рабочий процесс показывает, что для кодирования структура, которая сочетает итеративную самокоррекцию с внешней верификацией, превосходит более простые MAS проекты.

![][image4]

Рис. 4: (Предоставлено авторами): Платформа Multi-Agent System Search (MASS) - это трёхэтапный процесс оптимизации, который навигирует пространство поиска, охватывающее оптимизируемые промпты (инструкции и демонстрации) и конфигурируемые строительные блоки агентов (Aggregate, Reflect, Debate, Summarize, и Tool-use). Первый этап, блочная оптимизация промптов, независимо оптимизирует промпты для каждого модуля агента. Второй этап, оптимизация топологии рабочего процесса, семплирует валидные конфигурации системы из взвешенного влиянием пространства проектирования, интегрируя оптимизированные промпты. Финальный этап, оптимизация промптов уровня рабочего процесса, включает второй раунд оптимизации промптов для всей многоагентной системы после того, как оптимальный рабочий процесс из второго этапа был определен.

### 3. Оптимизация промптов уровня рабочего процесса:

Финальный этап включает глобальную оптимизацию промптов всей системы. После определения лучшей топологии промпты тонко настраиваются как единая, интегрированная сущность, чтобы убедиться, что они адаптированы для оркестрации и что взаимозависимости агентов оптимизированы. Например, после нахождения лучшей топологии для датасета DROP финальный этап оптимизации уточняет промпт агента "Предсказатель". Финальный, оптимизированный промпт высоко детализирован, начиная с предоставления агенту резюме самого датасета, отмечая его фокус на "экстрактивных ответах на вопросы" и "численной информации". Затем он включает примеры few-shot правильного поведения ответов на вопросы и формулирует основную инструкцию как сценарий высоких ставок: "Вы - высоко специализированный AI, задачей которого является извлечение критической численной информации для срочного новостного сюжета. Живая трансляция полагается на вашу точность и скорость". Этот многогранный промпт, сочетающий мета-знания, примеры и ролевую игру, настроен специально для финального рабочего процесса для максимизации точности.

### Ключевые находки и принципы:

Эксперименты демонстрируют, что MAS, оптимизированные MASS, значительно превосходят существующие вручную спроектированные системы и другие автоматизированные методы проектирования по спектру задач. Ключевые принципы проектирования для эффективных MAS, как выведено из этого исследования, троякие:

- Оптимизировать индивидуальных агентов с высококачественными промптами перед их компоновкой.
- Конструировать MAS путем компоновки влиятельных топологий, а не исследования неограниченного пространства поиска.
- Моделировать и оптимизировать взаимозависимости между агентами через финальную, совместную оптимизацию уровня рабочего процесса.

Опираясь на наше обсуждение ключевых техник рассуждений, давайте сначала рассмотрим основной принцип производительности: Закон масштабирования инференса для LLM. Этот закон утверждает, что производительность модели предсказуемо улучшается по мере увеличения вычислительных ресурсов, выделяемых ей. Мы можем видеть этот принцип в действии в сложных системах, таких как Deep Research, где AI агент использует эти ресурсы для автономного исследования темы, разбивая её на подвопросы, используя веб-поиск как инструмент и синтезируя свои находки.

**Deep Research.** Термин "Deep Research" описывает категорию AI агентных инструментов, разработанных для действия как неутомимые, методичные исследовательские помощники. Основные платформы в этой области включают Perplexity AI, исследовательские возможности Google Gemini и продвинутые функции OpenAI в рамках ChatGPT (см. Рис. 5).

![][image5]

Рис. 5: Google Deep Research для сбора информации

Фундаментальный сдвиг, внесенный этими инструментами, - это изменение в самом процессе поиска. Стандартный поиск предоставляет немедленные ссылки, оставляя работу синтеза вам. Deep Research работает на другой модели. Здесь вы поручаете AI сложный запрос и предоставляете ему "временной бюджет" - обычно несколько минут. В обмен на это терпение вы получаете детализированный отчет.

В течение этого времени AI работает от вашего имени агентным способом. Он автономно выполняет серию сложных шагов, которые были бы невероятно времязатратными для человека:

1. **Начальное исследование:** Он выполняет множественные, целенаправленные поиски на основе вашего начального промпта.

2. **Рассуждение и уточнение:** Он читает и анализирует первую волну результатов, синтезирует находки и критически выявляет пробелы, противоречия или области, которые требуют больше деталей.

3. **Последующий запрос:** На основе своих внутренних рассуждений он проводит новые, более нюансированные поиски для заполнения этих пробелов и углубления своего понимания.

4. **Финальный синтез:** После нескольких раундов этого итеративного поиска и рассуждения он компилирует всю валидированную информацию в единое, связное и структурированное резюме.

Этот систематический подход обеспечивает исчерпывающий и хорошо обоснованный ответ, значительно повышая эффективность и глубину сбора информации, тем самым облегчая более агентное принятие решений.

## Закон масштабирования инференса

Этот критический принцип диктует отношения между производительностью LLM и вычислительными ресурсами, выделяемыми во время её операционной фазы, известной как инференс. Закон масштабирования инференса отличается от более знакомых законов масштабирования для обучения, которые фокусируются на том, как качество модели улучшается с увеличением объема данных и вычислительной мощности во время создания модели. Вместо этого этот закон специально исследует динамические компромиссы, которые происходят, когда LLM активно генерирует вывод или ответ.

Краеугольный камень этого закона - откровение, что превосходные результаты часто могут быть достигнуты от сравнительно меньшей LLM путем увеличения вычислительных инвестиций во время инференса. Это не обязательно означает использование более мощного GPU, а скорее использование более сложных или ресурсоемких стратегий инференса. Яркий пример такой стратегии - инструктирование модели генерировать множественные потенциальные ответы - возможно, через техники, такие как разнообразный beam search или методы самосогласованности - а затем использование механизма выбора для определения наиболее оптимального вывода. Этот итеративный процесс уточнения или генерации множественных кандидатов требует больше вычислительных циклов, но может значительно повысить качество финального ответа.

Этот принцип предлагает критически важную платформу для информированного и экономически обоснованного принятия решений в развертывании агентных систем. Он бросает вызов интуитивному представлению, что большая модель всегда даст лучшую производительность. Закон утверждает, что меньшая модель, когда ей предоставлен более существенный "бюджет мышления" во время инференса, может иногда превосходить производительность гораздо большей модели, которая полагается на более простой, менее вычислительно интенсивный процесс генерации. "Бюджет мышления" здесь относится к дополнительным вычислительным шагам или сложным алгоритмам, применяемым во время инференса, позволяя меньшей модели исследовать более широкий спектр возможностей или применять более строгие внутренние проверки перед принятием ответа.

Следовательно, закон масштабирования инференса становится фундаментальным для построения эффективных и экономичных агентных систем. Он предоставляет методологию для тщательного балансирования нескольких взаимосвязанных факторов:

- **Размер модели:** Меньшие модели по своей природе менее требовательны в плане памяти и хранения.

- **Латентность ответа:** Хотя увеличенные вычисления во время инференса могут добавить к латентности, закон помогает определить точку, в которой прирост производительности перевешивает это увеличение, или как стратегически применить вычисления, чтобы избежать чрезмерных задержек.

- **Операционная стоимость:** Развертывание и запуск больших моделей обычно влечет более высокие постоянные операционные расходы из-за увеличенного потребления энергии и требований к инфраструктуре. Закон демонстрирует, как оптимизировать производительность без ненужного эскалации этих расходов.

Понимая и применяя закон масштабирования инференса, разработчики и организации могут делать стратегические выборы, которые ведут к оптимальной производительности для специфических агентных приложений, обеспечивая, что вычислительные ресурсы выделяются там, где они будут иметь наиболее значительное воздействие на качество и полезность вывода LLM. Это позволяет более нюансированные и экономически жизнеспособные подходы к развертыванию AI, выходя за рамки простой парадигмы "больше - значит лучше".

## Практический пример кода

Код DeepSearch, выложенный в открытый доступ Google, доступен через репозиторий gemini-fullstack-langgraph-quickstart (Рис. 6). Этот репозиторий предоставляет шаблон для разработчиков для построения полностековых AI агентов, используя Gemini 2.5 и фреймворк оркестрации LangGraph. Этот открытый стек облегчает экспериментирование с агентными архитектурами и может быть интегрирован с локальными LLM, такими как Gemma. Он использует Docker и модульное проектное скаффолдинг для быстрого прототипирования. Следует отметить, что этот релиз служит хорошо структурированной демонстрацией и не предназначен как готовый к производству бэкенд.

![][image6]

Рис. 6: (Предоставлено авторами) Пример DeepSearch с множественными шагами рефлексии

Этот проект предоставляет полностековое приложение с React фронтендом и LangGraph бэкендом, разработанное для продвинутых исследований и разговорного AI. LangGraph агент динамически генерирует поисковые запросы, используя модели Google Gemini, и интегрирует веб-исследования через Google Search API. Система использует рефлективные рассуждения для выявления пробелов в знаниях, итеративного уточнения поисков и синтеза ответов с цитированием. Фронтенд и бэкенд поддерживают горячую перезагрузку. Структура проекта включает отдельные директории frontend/ и backend/. Требования для настройки включают Node.js, npm, Python 3.8+ и Google Gemini API ключ. После настройки API ключа в .env файле бэкенда зависимости для бэкенда (используя pip install .) и фронтенда (npm install) могут быть установлены. Серверы разработки могут запускаться одновременно с make dev или индивидуально. Бэкенд агент, определенный в backend/src/agent/graph.py, генерирует начальные поисковые запросы, проводит веб-исследования, выполняет анализ пробелов в знаниях, итеративно уточняет запросы и синтезирует цитированный ответ, используя модель Gemini. Производственное развертывание включает бэкенд сервер, доставляющий статическую сборку фронтенда, и требует Redis для потокового вывода в реальном времени и базу данных Postgres для управления данными. Docker образ может быть собран и запущен с использованием docker-compose up, что также требует LangSmith API ключ для примера docker-compose.yml. Приложение использует React с Vite, Tailwind CSS, Shadcn UI, LangGraph и Google Gemini. Проект лицензирован под Apache License 2.0.

```python
# Создаём граф нашего агента
builder = StateGraph(OverallState, config_schema=Configuration)

# Определяем узлы, между которыми мы будем циклировать
builder.add_node("generate_query", generate_query)
builder.add_node("web_research", web_research)
builder.add_node("reflection", reflection)
builder.add_node("finalize_answer", finalize_answer)

# Устанавливаем точку входа как `generate_query`
# Это означает, что этот узел вызывается первым
builder.add_edge(START, "generate_query")

# Добавляем условное ребро для продолжения с поисковыми запросами в параллельной ветви
builder.add_conditional_edges(
    "generate_query", continue_to_web_research, ["web_research"]
)

# Рефлексируем над веб-исследованием
builder.add_edge("web_research", "reflection")

# Оцениваем исследование
builder.add_conditional_edges(
    "reflection", evaluate_research, ["web_research", "finalize_answer"]
)

# Финализируем ответ
builder.add_edge("finalize_answer", END)

graph = builder.compile(name="pro-search-agent")
```

Рис. 7: Пример DeepSearch с LangGraph (код из backend/src/agent/graph.py)

## Итак, что думают агенты?

В заключение, мыслительный процесс агента - это структурированный подход, который сочетает рассуждения и действия для решения проблем. Этот метод позволяет агенту явно планировать свои шаги, мониторить свой прогресс и взаимодействовать с внешними инструментами для сбора информации.

В своей основе "мышление" агента облегчается мощной LLM. Эта LLM генерирует серию мыслей, которые направляют последующие действия агента. Процесс обычно следует петле мысль-действие-наблюдение:

1. **Мысль:** Агент сначала генерирует текстовую мысль, которая разбивает проблему, формулирует план или анализирует текущую ситуацию. Этот внутренний монолог делает процесс рассуждений агента прозрачным и управляемым.

2. **Действие:** На основе мысли агент выбирает действие из предопределенного, дискретного набора опций. Например, в сценарии ответов на вопросы пространство действий может включать поиск онлайн, получение информации с конкретной веб-страницы или предоставление финального ответа.

3. **Наблюдение:** Агент затем получает обратную связь от своей среды на основе предпринятого действия. Это могут быть результаты веб-поиска или содержимое веб-страницы.

Этот цикл повторяется, с каждым наблюдением, информирующим следующую мысль, до тех пор, пока агент не определит, что достиг финального решения и не выполнит действие "завершить".

Эффективность этого подхода полагается на продвинутые способности рассуждений и планирования базовой LLM. Для направления агента фреймворк ReAct часто использует few-shot обучение, где LLM предоставляются примеры человекоподобных траекторий решения проблем. Эти примеры демонстрируют, как эффективно сочетать мысли и действия для решения похожих задач.

Частота мыслей агента может быть скорректирована в зависимости от задачи. Для знаниеемких задач рассуждения, таких как проверка фактов, мысли обычно переплетены с каждым действием для обеспечения логического потока сбора информации и рассуждений. В противоположность этому, для задач принятия решений, которые требуют многих действий, таких как навигация в симулированной среде, мысли могут использоваться более экономно, позволяя агенту решать, когда мышление необходимо.

## Краткий обзор

**Что:** Сложное решение проблем часто требует больше, чем единый, прямой ответ, представляя значительный вызов для AI. Основная проблема - обеспечение AI агентов способностью справляться с многошаговыми задачами, которые требуют логического вывода, декомпозиции и стратегического планирования. Без структурированного подхода агенты могут не справиться с тонкостями, приводя к неточным или неполным заключениям. Эти продвинутые методологии рассуждений направлены на то, чтобы сделать внутренний процесс "мысли" агента явным, позволяя ему систематически работать через вызовы.

**Почему:** Стандартизированное решение - это набор техник рассуждений, которые предоставляют структурированную платформу для процесса решения проблем агента. Методологии, такие как Chain-of-Thought (CoT) и Tree-of-Thought (ToT), направляют LLM к разбиению проблем и исследованию множественных путей решения. Самокоррекция позволяет итеративное уточнение ответов, обеспечивая более высокую точность. Агентные фреймворки, такие как ReAct, интегрируют рассуждения с действием, позволяя агентам взаимодействовать с внешними инструментами и средами для сбора информации и адаптации своих планов. Эта комбинация явных рассуждений, исследования, уточнения и использования инструментов создает более надежные, прозрачные и способные AI системы.

**Эмпирическое правило:** Используйте эти техники рассуждений, когда проблема слишком сложна для одноразового ответа и требует декомпозиции, многошаговой логики, взаимодействия с внешними источниками данных или инструментами, или стратегического планирования и адаптации. Они идеальны для задач, где показ "работы" или мыслительного процесса так же важен, как финальный ответ.

**Визуальное резюме**

![][image7]

Рис. 8: Шаблон проектирования рассуждений

## Ключевые выводы

- Делая свои рассуждения явными, агенты могут формулировать прозрачные, многошаговые планы, что является основополагающей способностью для автономного действия и пользовательского доверия.

- Фреймворк ReAct предоставляет агентам их основную операционную петлю, наделяя их способностью выходить за рамки простых рассуждений и взаимодействовать с внешними инструментами для динамического действия и адаптации в среде.

- Закон масштабирования инференса подразумевает, что производительность агента зависит не только от размера его базовой модели, но и от выделенного ему "времени мышления", позволяя более обдуманные и высококачественные автономные действия.

- Chain-of-Thought (CoT) служит как внутренний монолог агента, предоставляя структурированный способ формулирования плана путем разбиения сложной цели на последовательность управляемых действий.

- Tree-of-Thought и самокоррекция дают агентам критически важную способность к обдумыванию, позволяя им оценивать множественные стратегии, откатываться от ошибок и улучшать свои собственные планы перед выполнением.

- Совместные фреймворки, такие как Chain of Debates (CoD), сигнализируют о сдвиге от одиночных агентов к многоагентным системам, где команды агентов могут рассуждать вместе для решения более сложных проблем и уменьшения индивидуальных предвзятостей.

- Приложения, такие как Deep Research, демонстрируют, как эти техники кульминируют в агентах, которые могут выполнять сложные, долгосрочные задачи, такие как углубленное исследование, полностью автономно от имени пользователя.

- Для построения эффективных команд агентов фреймворки, такие как MASS, автоматизируют оптимизацию того, как инструктируются индивидуальные агенты и как они взаимодействуют, обеспечивая оптимальную работу всей многоагентной системы.

- Интегрируя эти техники рассуждений, мы строим агентов, которые не просто автоматизированы, но по-настоящему автономны, способные быть доверенными для планирования, действия и решения сложных проблем без прямого надзора.

## Заключения

Современный AI эволюционирует от пассивных инструментов к автономным агентам, способным решать сложные цели через структурированные рассуждения. Это агентное поведение начинается с внутреннего монолога, поддерживаемого техниками, такими как Chain-of-Thought (CoT), которые позволяют агенту формулировать связный план перед действием. Истинная автономия требует обдумывания, которого агенты достигают через самокоррекцию и Tree-of-Thought (ToT), позволяя им оценивать множественные стратегии и независимо улучшать свою собственную работу. Ключевой скачок к полностью агентным системам происходит от фреймворка ReAct, который наделяет агента способностью выходить за рамки мышления и начинать действовать, используя внешние инструменты. Это устанавливает основную агентную петлю мысли, действия и наблюдения, позволяя агенту динамически адаптировать свою стратегию на основе обратной связи от среды.

Способность агента к глубокому обдумыванию подпитывается законом масштабирования инференса, где больше вычислительного "времени мышления" напрямую переводится в более надежные автономные действия. Следующий рубеж - многоагентная система, где фреймворки, такие как Chain of Debates (CoD), создают совместные агентные сообщества, которые рассуждают вместе для достижения общей цели. Это не теоретическое; агентные приложения, такие как Deep Research, уже демонстрируют, как автономные агенты могут выполнять сложные, многошаговые исследования от имени пользователя. Всеобъемлющая цель - проектировать надежных и прозрачных автономных агентов, которым можно доверить независимое управление и решение сложных проблем. В конечном счете, сочетая явные рассуждения со способностью действовать, эти методологии завершают трансформацию AI в по-настоящему агентных решателей проблем.

## Ссылки

Релевантные исследования включают:

1. "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" by Wei et al. (2022)

2. "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" by Yao et al. (2023)

3. "Program-Aided Language Models" by Gao et al. (2023)

4. "ReAct: Synergizing Reasoning and Acting in Language Models" by Yao et al. (2023)

5. Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for LLM Problem-Solving, 2024

6. [Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies](https://arxiv.org/abs/2502.02533)

[image1]: ../Assets/chapter-17-image1.png
[image2]: ../Assets/chapter-17-image2.png
[image3]: ../Assets/chapter-17-image3.png
[image4]: ../Assets/chapter-17-image4.png
[image5]: ../Assets/chapter-17-image5.png
[image6]: ../Assets/chapter-17-image6.png
[image7]: ../Assets/chapter-17-image7.png

---

## Навигация

**Назад:** [Глава 16. Оптимизация с учетом ресурсов](Глава%2016.%20Оптимизация%20с%20учетом%20ресурсов.md)  
**Вперед:** [Глава 18. Паттерны безопасности и защитные механизмы](Глава%2018.%20Паттерны%20безопасности%20и%20защитные%20механизмы.md)
